---
title: "Act-Learn Sequence"
author: "Kyle MacDonald"
date: "September 30, 2015"
output: html_document
---

```{r, echo = F}
rm(list=ls()) # clear workspace
knitr::opts_chunk$set(warning=FALSE, message=FALSE, sanitize = T, 
                      fig.height=6, fig.width=9, echo=F, cache = T)

```


This script analyzes data from an experiment testing the effectiveness of different sequences of active
vs. passive training in a category learning task. 

In this experiment, we only ran the rule-based (easier, 1-D category structure). The hypothesis is that getting a block of receptive data will make participants more effective active learners, boosting their accuracy on test trials. 

## Libraries 

```{r libraries, warning=F, message=F, comment=F}
source("helpers/useful.R")
library(langcog)
library(dplyr)
library(magrittr)
library(directlabels)
```

## Load data

Sequence data and Yoked data.

```{r load data}
df1 <- read.csv("../data/act-learn-sequence-1.csv", stringsAsFactors = F)
df2 <- read.csv("../data/act-learn-ii-rb-yoked.csv", stringsAsFactors = F)
df3 <- read.csv("../data/act-learn-replication-first2-blocks.csv", stringsAsFactors = F)
```

Some munging, so we can merge.

```{r}
df1 %<>% mutate(age = as.character(age),
                odb_stim = as.character(odb_stim),
                odb_param = as.character(odb_param),
                trial_number = as.character(trial_number),
                block_factor = as.factor(block)) %>% 
    select(-scale_factor_orientation)

df2 %<>% mutate(trial_training_block = condition,
                block = as.numeric(block),
                block_factor = as.factor(block)) %>% 
    select(-scale_factor_orientation)

df3 %<>% mutate(trial_training_block = condition,
                category_type = "rule-based",
                age = as.character(age),
                odb_stim = as.character(odb_stim),
                odb_param = as.character(odb_param),
                trial_number = as.character(trial_number),
                block_factor = as.factor(block)) %>% 
    select(-X, - confidence, -include, -radius_trial)
```

Now merge.

```{r}
df <- bind_rows(df1, df2, df3)
```

```{r, echo = F, eval = F}
df_comments <- df %>% 
    select(subids, condition, category_type, order, understand, comments) %>% 
    distinct() %>% 
    arrange(condition, category_type, order, understand)
    
write.csv(df_comments, "act-learn-comments.csv")
```

## Exclusionary criteria

Overall performance (averaged across blocks) was more than three standard deviations below the mean of their group.

```{r exclusionary}
ss <- df %>%
    filter(trial_type == "test") %>%
    group_by(subids, condition) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high_acc = ci.high(correct),
              ci_low_acc = ci.low(correct))

# get the mean and standard deviation of each group
ms_ss <- ss %>%
    group_by(condition) %>%
    summarise(group_mean = mean(mean_accuracy),
              group_sd = sd(mean_accuracy))
```

Map means and sd to variables

```{r}
# active rb
mean_act_rb <- filter(ms_ss, condition == "active_receptive")$group_mean
sd_act_rb <- filter(ms_ss, condition == "receptive_active")$group_sd


# receptive rb
mean_rec_rb <- filter(ms_ss, condition == "active_receptive")$group_mean
sd_rec_rb <- filter(ms_ss, condition == "receptive_active")$group_sd
```

Flag subject means that are +/- 3sd 

```{r}
ss_include <- ss %>%
    mutate(
        include = ifelse(condition == "active_receptive", 
                         ifelse(mean_accuracy > mean_act_rb + 3 * sd_act_rb | 
                                    mean_accuracy < mean_act_rb - 3 * sd_act_rb, "remove", "include"),
                         ifelse(mean_accuracy > mean_rec_rb + 3 * sd_rec_rb | 
                                    mean_accuracy < mean_rec_rb - 3 * sd_rec_rb, "remove", "include"))) %>% 
    select(subids, include, condition) 

ss_include %>%
    group_by(condition, include) %>%
    summarise(n())

# merge with full data frame
df <- left_join(df, select(ss_include, subids, include, condition), by = c("subids", "condition"))

# filter out subjects that are +/- 3sd
df <- df %>% filter(include == "include")
```

## Remove participants who did not understand the task

```{r}
df %<>% filter(understand == "Yes")
```


## Descriptives

```{r demographics, echo=FALSE}
demo_df <- df %>% 
    distinct(subids) %>% 
    xtabs(formula = ~ condition + category_type + order) %>% 
    as.data.frame() %>% 
    rename(count = Freq)

demo_df <- df %>% 
    group_by(subids, condition, order) %>%
    summarise(exp_length_minutes = sum(rt) / 60000) %>% 
    group_by(condition, order) %>% 
    summarise(mean_exp_length = mean(exp_length_minutes),
              sd_exp_length = sd(exp_length_minutes)) %>% 
    left_join(demo_df, by = c("condition", "order"))
    
knitr::kable(demo_df)
```

Histogram of length of experiment split by condition 

```{r, echo=F}
ss_rt <- df %>%
    group_by(subids, condition) %>%
    summarise(exp_length_min = sum(rt) / 60000)

qplot(exp_length_min, data=ss_rt, facets=.~condition)
```

## Overall accuracy analysis 

Rename conditions and reorder levels of the condition factor.

```{r}
df %<>% mutate(condition = factor(condition)) 
levels(df$condition) <- c("AA", "AR", "RR", "RA", "YY")
df$condition <- factor(df$condition, levels = c("AA", "RR", "RA", "AR", "YY"))
```

Get mean accuracy for each condition and category type

```{r, echo=F}
ms <- df %>%
    filter(trial_type == "test") %>%
    group_by(condition, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))
```

Plot.

```{r mean acc plot condition/order, echo=F, fig.width=14}
qplot(x=condition, y=mean_accuracy, data=ms,
      geom="bar", stat="identity", fill = condition, position = "dodge") + 
    geom_linerange(aes(ymin=mean_accuracy - ci_low, 
                       ymax=mean_accuracy + ci_high), 
                   width = .05, size=0.6, position=position_dodge(width=0.9)) + 
    coord_cartesian(ylim=c(0.5,1)) +
    scale_fill_solarized() +
    ylab("Mean Accuracy") +
    xlab("Condition") +
    facet_grid(.~category_type) +
    theme(text = element_text(size=16))
```

Overall, receptive-first learners are numerically more accurate, but the difference is not reliable. 

## Accuracy by block analysis

Next, we analyze accuracy across the two blocks.

```{r acc by block, echo=F}
ms_block <- df %>%
    filter(trial_type == "test") %>%
    group_by(condition, block, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))
```

Plot.

```{r acc by block plot, echo=F}
block_plot <- qplot(x=block, y=mean_accuracy, data=ms_block, color = condition,
      geom=c("blank"), stat="identity") +
    geom_smooth(method = "lm", se=F) +
    geom_pointrange(aes(ymin=mean_accuracy - ci_low, 
                       ymax=mean_accuracy + ci_high), 
                   width = .05, size=0.6) + 
    scale_x_discrete() +
    scale_y_continuous(limits=c(0.5,1)) +
    scale_color_solarized() +
    facet_grid(.~category_type) + 
    ylab("Mean Accuracy") +
    xlab("Block") +
    guides(color = F) +
    theme(text = element_text(size=16)) 

direct.label(block_plot, list(last.bumpup, hjust = -0.5))
```

The block analysis suggests some effect of order on active learning. Receptive-first learners appear to be
more accurate after their block of active learning (block 2) compared to Active-first (block 1). 

But, the effect is not large enough to overcome the overall active advantage that shows up in block 1 for the Active-first learners.

## Accuracy by block and order 

Order here refers to whether size or angle was the category dimension.

* Order 1 = Size
* Order 2 = Angle

```{r acc by block and dimension, echo=F}
ms_block_order <- df %>%
    filter(trial_type == "test") %>%
    group_by(condition, block_factor, order, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))
```

Plot accuracy over blocks

```{r acc by block and dim plot, echo=F}
block_plot2 <- qplot(x=block_factor, y=mean_accuracy, data=ms_block_order, color = condition, 
      group = condition,
      geom=c("point", "line"), stat="identity", facets=category_type~order) + 
    geom_linerange(aes(ymin=mean_accuracy - ci_low, 
                       ymax=mean_accuracy + ci_high), 
                   width = .05, size=0.6) + 
    scale_color_solarized() +
    scale_y_continuous(limits=c(0.45,1)) +
    scale_x_discrete() +
    ylab("Mean Accuracy") +
    xlab("Block") +
    theme(text = element_text(size=16)) +
    theme_bw()

direct.label(block_plot2, list(last.bumpup, hjust = -0.5))
```

Order 1 (Size) looks like what we predicted: A small boost for Receptive-first learners. 

In Order 2 (Angle), there is a bigger difference between active and passive learning in the first block, with receptive learning being the hardest. But, we have the least amount of data for this condition (only 5
participants in Receptive-first, Order 2 condition). 


## Evidence selection analysis (active learning)

Analyze the average distance of participants' samples from the optimal decision
boundary.

```{r sampling data, echo=F}
df %<>% mutate(trial_training_block = ifelse(condition == "active_receptive" & block == 1, "active",
                                             ifelse(condition == "receptive_active" & block == 2,
                                             "active", "receptive")))


df_sampling <- df %>% filter(trial_type == "training", trial_training_block == "active")
```

Rotate, so orientation and radius are on the same dimension.

* dim of interest = dimension with category boundary
* other dim = dimension that does not contain the category boundary 

```{r rotate samples, echo=F}
df_sampling <- df_sampling %>%
    mutate(dim_of_interest = ifelse(odb_scale == "orientation",
                                    orientation_response_param,
                                    radius_response_param),
           other_dim = ifelse(odb_scale == "orientation",
                              radius_response_param,
                              orientation_response_param))
```

Plot group level sampling behavior.

```{r sampling plot, fig.width=8}
qplot(x=dim_of_interest, y=other_dim, data = df_sampling,
      facets=~condition, color = trial_category) +
    scale_color_brewer(type = "qual", palette = "Set1") +
    geom_vline(xintercept = 300, color = "blue")
```

```{r}
df_sampling$dim_ref <- ifelse(df_sampling$dim_of_interest <= 300, 
                              df_sampling$dim_of_interest, 
                              600 - df_sampling$dim_of_interest)
ggplot(data = df_sampling,
       aes(x = dim_ref, fill=condition)) + 
    geom_histogram(aes(y=..density..),
                   position = "dodge",
                   binwidth = 50) +
    xlim(0,300) +
    scale_fill_solarized()
```

Plot individual participant sampling behavior

```{r sampling subs, echo=F, fig.width=12, fig.height=8}
qplot(x=dim_of_interest, y=other_dim, data=df_sampling,
      color = condition) +
    facet_wrap(condition~subids) +
    geom_vline(aes(xintercept=300)) 
```

Get distance from optimal decision boundary for each sample.

```{r}
df_sampling <- mutate(df_sampling, 
                      samp_dist_odb = ifelse(odb_scale == "orientation",
                                             abs(as.numeric(odb_param) - orientation_response_param),
                                             abs(as.numeric(odb_param) - radius_response_param)))
```

Now get the average distance across subjects

```{r}
ms_sampling <- df_sampling %>%
    group_by(condition, order) %>%
    summarize(mean_samp_dist = mean(samp_dist_odb),
              ci_high = ci.high(samp_dist_odb),
              ci_low = ci.low(samp_dist_odb))
```

Plot.

```{r}
qplot(x=condition, y=mean_samp_dist, data=ms_sampling,
      geom="bar", stat="identity", fill = condition, position = "dodge") + 
    geom_linerange(aes(ymin=mean_samp_dist - ci_low, 
                       ymax=mean_samp_dist + ci_high), 
                   width = .05, size=0.6, position=position_dodge(width=0.9)) + 
    scale_fill_brewer(type = "qual", palette = "Set1") +
    coord_cartesian(ylim=c(100, 190)) +
    ylab("Mean Sample Distance") +
    xlab("Condition") +
    facet_grid(.~order) +
    theme(text = element_text(size=16)) +
    theme_classic() 
```

Active learning is better after getting a block of receptive learning trials. Some evidence that getting receptive-first boosted active learning. 

## Relationship between sampling and test

Get the mean sample distance and accuracy for each participant.

```{r}
ss_samp_dist <- df_sampling %>%
    filter(trial_training_block == "active") %>%
    group_by(subids, condition, order) %>%
    summarise(mean_samp_dist = mean(samp_dist_odb),
              ci_high_msd = ci.high(samp_dist_odb),
              ci_low_msd = ci.low(samp_dist_odb))

ss_mean_acc_active_block <- df %>%
    filter(trial_training_block == "active", trial_type == "test") %>%
    group_by(subids, condition) %>%
    summarise(mean_accuracy_active_block = mean(correct),
              ci_high_acc_active_block = ci.high(correct),
              ci_low_acc_active_block = ci.low(correct))

ss_mean_acc_all <- df %>%
    filter(trial_type == "test") %>%
    group_by(subids, condition) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high_acc = ci.high(correct),
              ci_low_acc = ci.low(correct))

# join sampling and test acc together
ss_all <- left_join(ss_samp_dist, ss_mean_acc_active_block, by=c("subids", "condition"))
ss_all <- left_join(ss_all, ss_mean_acc_all, by=c("subids", "condition"))
```

Plot

```{r}
qplot(x=mean_samp_dist, y=mean_accuracy, data=ss_all) +
    geom_smooth(method="lm") +
    facet_grid(~condition) +
    xlab("Mean Sample Distance") +
    ylab("Mean Accuracy") +
    theme(text = element_text(size=16))
```


## Individual accuracy across blocks: consistency analysis

```{r, fig.height=9, fig.width=14}
ss_mean_acc_explore <- df %>%
    filter(trial_type == "test", order == "order1") %>%
    group_by(subids, condition, block, order, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high_acc = ci.high(correct),
              ci_low_acc = ci.low(correct))

```

Plot.

```{r}
qplot(x=as.factor(block), y=mean_accuracy, data=ss_mean_acc_explore, 
      color = as.factor(subids), group = as.factor(subids), shape = order) +
    geom_line() +
    geom_smooth(aes(group=1), method = "lm", se = F, color = "red", size = 2) +
    facet_grid(category_type~condition) +
    xlab("Block") +
    ylab("Mean Accuracy") +
    theme(text = element_text(size=16)) +
    guides(color = F)
```

Not totally sure what to make of this. But there is a different overall pattern of accuracy performance across blocks. Active-first learners have smaller slope compared to Receptive-first learners. 

There are a couple of participants doing weird things -- huge drop in accuracy in block 2, but show up in both conditions. 

Maybe there are some other analyses to do at the individual participant level? 

## Statistics 

t.test testing difference in accuracy on test trials between active first and receptive first learning conditions.

```{r}
t.test(mean_accuracy ~ condition, var.equal=TRUE, data=ss_all)
```

Overall accuracy scores of the two groups are not different.

```{r}
t.test(mean_accuracy_active_block ~ condition, var.equal=TRUE, data=ss_all)
```

Accuracy on active learning block is trending towards a reliable difference. (Is marginally significant if you just look at Order 1, size condition).

## Models

### Accuracy on the trial-level based on condition and block

Does condition and block predict accuracy on test trials?

```{r}
m1 <- glmer(correct ~ condition * block + (1|subids), 
            data=filter(df, category_type == "rule-based", trial_type=="test"), family=binomial) 
summary(m1)
```

Reliable interaction between condition and block. Receptive-first learners perform better on the second block of test trials than Active-first learners. 

But overall, the two groups are not different from one another. How to interpret? 

### Accuracy based on sampling behavior and condition

Does mean accuracy depend on sampling behavior and condition?

```{r}
m2 <- lm(mean_accuracy ~ mean_samp_dist * condition, data=ss_all)
summary(m2)
```

Reliable interaction between mean sample distance and condition. If you get Receptive-first, then better sampling predicts better test, but not if you get Active-first.

### Sampling behavior based on condition

Which condition is "better" at sampling?

```{r}
m3_samp <- lmer(samp_dist_odb ~ condition + (1|subids), data=df_sampling)
summary(m3_samp)
```

Receptive-first participants are better at sampling than active first participants.
