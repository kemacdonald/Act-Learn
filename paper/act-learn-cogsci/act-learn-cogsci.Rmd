---
title: "How should we structure learning contexts? Understanding the mix of active and passive learning"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Kyle MacDonald} \\ \texttt{kyle.macdonald@university.edu} \\ Department of Psychology \\ Stanford University
    \And {\large \bf Michael C. Frank} \\ \texttt{mcfrank@university.edu} \\ Department of Psychology \\ Stanford University}

abstract: >
    Much of what we know is a result of contexts that contain *both* active and passive learning. But how should we structure the environment in order to maximize learning outcomes? In the current work, we explore how different sequences of active and passive training affect concept learning in adults. First, we replicate the active over passive learning advantage found in @markant2014better (Experiments 1a and 1b). Then in Experiment 2, we provide a direct test of how different sequences of active/passive training affect people's learning outcomes. Across both experiments, active training leads to better overall learning of the target concept compared to passive training. Interestingly, in Experiment 2 "passive-first" learners performed better than "active-first" learners. These data provide evidence that active learning can be more effective after people have constructed a stronger representation of the learning task.
    
keywords:
    "self-directed learning, concept learning, replication"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=T, message=F, sanitize = T)
```

```{r libraries}
source("../../analysis/helpers/useful.R")
library(langcog)
library(dplyr)
library(magrittr)
library(directlabels)
library(png)
library(grid)
library(ggplot2)
library(xtable)
```

```{r binomial-smoother}
binomial_smooth <- function(...) {
    geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)
}
```

```{r data}
df <- read.csv("../../data/act-learn-all-data-tidy.csv", stringsAsFactors = F)
```

```{r data cleaning}
# Rename conditions and reorder levels of the condition factor.
df %<>% mutate(condition_long = condition,
               condition = factor(condition),
               condition_short = factor(condition),
               category_type_string = category_type,
               framing_condition_string = framing_condition,
               category_type = factor(category_type),
               odb_scale = ifelse(odb_scale == "radius_scale", "radius", 
                                  ifelse(odb_scale == "orientation_scale", "orientation",
                                         odb_scale)))

# rename levels of condition variable
levels(df$condition) <- c("AA", "AR", "RA", "RR", "YY")
df$condition <- factor(df$condition, levels = c("AA", "RA", "AR", "RR", "YY"))

# rename and reorder levels of category type variable
levels(df$category_type) <- c("Info-Integration", "Rule-Based")
df$category_type <- factor(df$category_type, levels = c("Rule-Based", "Info-Integration")) 
levels(df$framing_condition) <- c("Info-Integration", "None", "Rule-Based")

# rename levels of condition_short variable
levels(df$condition_short) <- c("A", "AR", "RA", "R", "Y")
df$condition_short <- factor(df$condition_short, levels = c("A", "RA", "AR", "R", "Y"))
```

# Introduction

Learning is the result of a complex interaction of active and passive processes. It is almost impossible to think of a case where people learn a concept entirely from information that they generate themselves (active learning) or entirely from information generated from the world (passive learning). And yet we know relatively little about how to best structure the sequence of active and passive learning in order to maximize learning outcomes. For example, consider a teacher introducing a challenging math concept: should she allow students to explore first and then provide instruction, or should she teach first and then let students actively explore? 

The potential advantage for active learning has been the focus of research in education [@grabinger1995rich], machine learning [@settles2012active], and cognitive science [@castro2009human]. In the majority of these studies, researchers isolate active and passive training, and test which regime leads to better learning outcomes. In their review of this literature, @gureckis2012self present a set a general "cognitive" explanations for why active learning might be helpful across different tasks and learning contexts. One explanation is that people can use their prior experience to select the most informative examples (e.g., asking a question about something that is particularly confusing). Another explanation is that the process of active learning causes people to engage more deeply with the task, allowing them to develop better learning strategies.[^1] But @gureckis2012self point out that the effectiveness of selection-based learning is fundamentally linked to the quality of the learner's *representation of the task*. If the representation is poor, or there is a prior misconception, then active learning will not be effective and might even lead to biased information seeking (e.g., confirmation bias [@nickerson1998confirmation]).

[^1]: This idea is similar to work showing that simply providing an explanation can deepen understanding of a concept [@lombrozo2006structure].

These cognitive explanations lead to competing predictions about the effectiveness of different sequences of active and passive learning. One prediction is that receiving active learning first (active-first) is better because it engages learners and allows them to develop better learning strategies. Research from education on the concept of *Productive Failure* shows that allowing students to first struggle (typically in the form of self-directed problem solving) with a task, leads to better uptake of subsequent instruction [@westermann2012delaying]. Moreover, in a tightly controlled cross-situational word learning task, @kachergis2013actively found that people who received active learning first preformed better overall when asked to recall newly learned words. @kachergis2013actively suggest that learners developed better attentional and memory strategies during the active training, which transferred to passive learning context, increasing overall acccuracy.

The competing prediction is that receiving passive learning first (passive-first) is better because it helps to set up a stronger task representation, allowing people to use their subsequent active learning more effectively. Evidence in support of this prediction comes from research that explores the contexts when the active learning advantage breaks down. For example, in a category learning task, @markant2014better found that active learning provided no benefit over passive learning when the target category structure was different from people's prior expectations. They suggest that the separation between expectation and concept caused people to select less helpful examples. In addition, work from machine learning shows that in practical settings random sampling is preferable to active learning when the correct model class (i.e., representation of the task) is unknown [@settles2012active].  

```{r stimuli_exp1, fig.env = "figure*", fig.pos = "t", fig.width=6, fig.height=2.5, fig.align='center', set.cap.width=T, num.cols.cap=2, fig.cap = "The left panel shows a screenshot of the stimuli used in Experiments 1 and 2. The right panel shows examples of distributions of training stimuli shown to participants in the passive learning condition. Each point represents a different antenna, constructed with an orientation value (vertical axis) and radius value (horizontal axis). The color of the points show the category membership of each antenna (red is Channel 1, blue is Channel 2). The solid line in each facet represents  the optimal category boundary for both the Rule-Based category and the Information-Integration category structures."}

grid::grid.raster(png::readPNG("figs/stimuli.png"))
```

In the current work, we set out to test these two predictions by exploring the effectiveness of different sequences of active/passive learning. We use a category learning paradigm from @markant2014better, where they found a reliable advantage for active over passive learning. In this task, people learn one of two abstract categories: a Rule-Based (RB) structure where the category boundary varied along a single dimension (e.g., size), and a more complex Information-Integration (II) structure where the category boundary was defined by two dimensions (e.g., size and angle). Active learners generate their own examples to test their beliefs; whereas passive learners receive examples that were generated randomly. 

We predicted that passive-first training would be better in this task because learners can generate and refine hypotheses during the passive block, which they then refine with highly informative examples in the active block. Moreover, @markant2014better found that the quality of sampling behavior was "worse than random in the early blocks of their experiment, suggesting that active learning was less effective early in the task. 

The plan of the paper is as follows: In Experiments 1a, we present a direct replication of the active learning advantage found in @markant2014better for the RB category structure. In Experiment 1b, we test the more complex II category structure. Then, in Experiment 2, we build on our replication data to show that passive-first training is more effective compared to active-first training. Together, the data suggest that active learning can provide an advantage over passive learning, but this advantage depends on the learner's representation of the task, which can be improved by receiving more experience with the task. 

# Experiment 1a

Experiment 1a is a direct replication of the advantage for active learning over passive learning found in @markant2014better. We tested participants' category learning for the RB category structure after receiving either active or passive training. We used the same stimuli and followed the exact procedures as the original study (described below). All of the stimuli and the experiments can be viewed and downloaded at the project page for this paper: https://kemacdonald.github.io/Act-Learn/. 

```{r exp1a-replication-data}
df_rep <- df %>% 
    filter(experiment == "replication_1a", 
           condition_short %in% c("A","R"), 
           category_type == "Rule-Based")
```

```{r rep1a-acc-computation}
ms_rep <- df_rep %>%
    filter(trial_type == "test") %>%
    group_by(condition_short, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))

ms_rep_block <- df_rep %>%
    filter(trial_type == "test") %>%
    group_by(condition_short, category_type, block) %>%
    summarise(mean_accuracy = mean(correct, na.rm=T),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))

ss_rep <- df_rep %>%
    filter(trial_type == "test") %>%
    group_by(condition_short, category_type, subids, experiment) %>%
    summarise(mean_accuracy = mean(correct, na.rm=T),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))
```

```{r exp1a_t-test}
rep1a_t_test <- t.test(mean_accuracy ~ condition_short, var.equal=TRUE, 
                       data=filter(ss_rep, experiment == "replication_1a"))
```

```{r exp1a_acc_plot, fig.env = "figure*", fig.pos = "t", fig.width=5, fig.height=2.5, fig.align='center', set.cap.width=T, num.cols.cap=2, fig.cap = "The left panel shows overall accuracy performance for the Active and Passive training conditions. The right panel shows participants' accuracy across each of the six blocks in the experiment. Colored lines are generated by a binomial smoother and error bars indicate 95\\% confidence intervals computed by non-parametric bootstrap."}

acc_plot_1a <- ggplot(aes(x=condition_short, y=mean_accuracy), data=ms_rep) + 
    geom_bar(stat = "identity", aes(fill = condition_short)) + 
    geom_linerange(aes(ymin=mean_accuracy - ci_low, 
                       ymax=mean_accuracy + ci_high), 
                   size=0.6,
                   position=position_dodge(width=0.9)) + 
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    facet_grid(.~category_type) +
    coord_cartesian(ylim=c(0.4,1.0)) +
    scale_fill_solarized() +
    ylab("Mean Accuracy") +
    xlab("Condition") +
    facet_grid(.~category_type) +
    theme(text = element_text(size=16)) +
    guides(fill=F) +
    theme_bw()

block_plot_exp1 <- ggplot(aes(x=as.numeric(block), y=mean_accuracy, color = condition_short), 
                          data=filter(ms_rep_block, category_type == "Rule-Based")) +
    binomial_smooth() +
    geom_pointrange(aes(ymin=mean_accuracy - ci_low, 
                        ymax=mean_accuracy + ci_high,
                        color = condition_short), 
                    size=0.3) +
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    facet_grid(.~category_type) +
    scale_y_continuous(limits=c(0.4,1.0)) +
    scale_x_continuous(limits=c(0.5,6.5), breaks = seq(1:6)) +
    scale_color_solarized() +
    ylab("Mean Accuracy") +
    xlab("Block") +
    guides(color = F) +
    theme(text = element_text(size=16)) +
    theme_bw()

block_plot_exp1 <- direct.label(block_plot_exp1, list(last.points, hjust = -0.5))
gridExtra::grid.arrange(acc_plot_1a, block_plot_exp1, ncol = 2, widths = c(2.5,3))
```

## Methods

### Power analysis and planned sample

We calculated Cohenâ€™s d for the test comparing overall accuracy between the active and passive learning conditions (d = 0.47). Next we conducted a post hoc power analysis and found that the original study achieved a power of %43. Finally, we conducted an a priori power analysis for the proposed replication in order to achieve 80%, 90%, and 95% power to detect that effect size. The results were: 80% (n = 84, 42 in each group), 90% (n = 158, 79 in each group), and 95% (n = 238, 119 in each group). Our planned sample size was 48 participants, 24 in each condition. This sample size allowed us to achieve 47% power to detect the an effect the size of the original finding. This sample size was chosen to maximize power within our funding constraints. 

### Participants

```{r rep1a-demographics}
demographics_replication <- df_rep %>% 
    distinct(subids) %>% 
    xtabs(formula = ~ condition_long + category_type_string) %>% 
    as.data.frame() %>% 
    rename(count = Freq)

dnu_exp1a <- df_rep %>% distinct(subids) %>% count(understand) %>% filter(understand == "No")

n_active_rep_1a <- demographics_replication$count[1]
n_passive_rep_1a <- demographics_replication$count[2]
```

We posted a set of Human Intelligence Tasks (HITs) to Amazon Mechanical Turk. Only participants with US IP addresses and a task approval rate above 85% were allowed to participate, and each HIT paid one dollar. Approximately 25 HITs were posted for each of the two between-subjects conditions. Data were excluded if participants completed the task more than once or if they reported that they did not understand the task at the end of the experiment (`r dnu_exp1a$n` HITs). The final sample consisted of `r (n_passive_rep_1a + n_active_rep_1a) - dnu_exp1a$n` participants. 

```{r data-filter-1a}
df_rep %<>% filter(understand != "No")
```

### Stimuli

The left panel of Figure 1 shows a screenshot of the stimuli used in across all experiments. Visual stimuli were black "antennas" on a white background. Each antenna could vary along two continuous dimensions -- radius size or central angle -- and was assigned a value between 1 and 600. These values were converted to pixel values for display on a computer screen. To ensure that participants could not complete a full rotation of the antenna, the rotation of the central angle was limited to 150 degrees. The minimum radius and angle values were randomized for each participant, such that each participant was assigned a unique optimal decision boundary. Finally, we used a Rule-Based category structure where the category boundary is defined along a single dimension: either the antenna's size or central angle (see the right panel of Figure 1). 

Radius and angle values for the 96 passive training trials were generated from two Gaussian distributions with identical mean and covariance parameters as @markant2014better (see the right panel of Figure 1). For test trials, we created a uniform grid of 192 unique test items that covered the entire feature space. We randomly sampled 8 items from each quadrant to get 32 test trials for each block. We then randomized the order of the training and test trials within each block for each participant. 

### Design and procedure

Participants saw a total of 288 trials (96 training trials and 192 test trials) across 6 blocks. Each block consisted of 16 training trials and 32 test trials. Before starting the task, participants were told that this was a game where they would see "loop antennas" for televisions and each antenna received one of two channels (CH1 or CH2), and their goal was to learn the difference between the two types of antennas. We introduced some uncertainty by telling participants that the antennas could pick up the wrong channel on occasion, and that they should learn what channel is most often received by a particular type of antenna.

After the instructions, participants were randomly assigned to one the two between-subjects conditions (Active vs. Passive training). In the Active training condition, participants were able to design their own antennas to test. They modified the antenna by clicking and dragging the mouse from left to right. To change the size of the antenna, they first pressed the "Z" key. To change the angle, they first pressed the "X" key. When participants were finished with their design, they pressed the spacebar to see which channel (Ch1 or Ch2) the antenna received. The channel label appeared in a text box with a green border located above the antenna.

In the Passive training condition, participants were shown antennas with size and angles generated from the underlying category distributions. After a two second delay they were told which channel the antenna received. To ensure that participants saw the channel, they had to click on the channel text in order to advance the experiment. When they clicked the channel text, a green box appeared around the text to indicate that their response had been recorded.

After completing the training, participants in both conditions proceeded to the test trials. On each test trial participants saw an antenna and were asked, "Which channel does this antenna receive?" To indicate their response participants selected one of two buttons located above the antenna. At the end of each block of test trials, participants saw a summary of their accuracy on the preceding block.

## Results and Discussion

### Overall classification accuracy

We directly followed the analysis plan of @markant2014better, using a t-test to compare overall test performance for participants in the active and the passive learning conditions. \footnote{All of our data, processing, and analysis code can be viewed in the version control repository for this paper at: https://github.com/kemacdonald/act-learn.} The left panel of Figure 2 shows overall test performance, with active learners being more accurate than passive learners, $t$(`r rep1a_t_test$parameter`) = `r round(rep1a_t_test$statistic, 2)`, $p$ = `r round(rep1a_t_test$p.value, 3)`. 

### Classification accuracy across blocks

```{r}
mix_model_exp1a <- glmer(correct ~ condition * block + (1|subids), 
            data=filter(df_rep,trial_type=="test"), family=binomial) 
```

The right panel of Figure 2 shows participants' accuracies across blocks in the experiment. To quantify participants' behavior, we use mixed effects regression models with the maximal random effects structure justified by our experimental design: by-subject intercepts. We fit a logistic regression predicting test performance based on condition (active/passive) and block. The model was specified as \texttt{Correct $\sim$ 1 + Condition * Block + (1 | subject)}. We found a significant main effect of condition ($\beta$ = `r round(summary(mix_model_exp1a)$coef[2], 2)`, p < .001) with better performance for active learners, and a significant main effect of block ($\beta$ = `r round(summary(mix_model_exp1a)$coef[3], 2)`, p < .001) such that responses were more accurate later in the experiment.

### Relationship between sampling behavior and learning

```{r sampling-data}
df_rep_all <- df %>% filter(condition =="AA", category_type == "Rule-Based")
df_sampling_exp1 <- df %>% filter(condition == "AA", category_type == "Rule-Based", trial_type == "training")
```

```{r avg_samp_dist_trials}
df_sampling_exp1 <- mutate(df_sampling_exp1, 
                      samp_dist_odb = ifelse(odb_scale == "orientation" & category_type == "Rule-Based", 
                                             abs(as.numeric(odb_param) - orientation_response_param),
                                             ifelse(odb_scale == "radius" & category_type == "Rule-Based", 
                                                    abs(as.numeric(odb_param) - radius_response_param),
                                                    abs(orientation_response_param - radius_response_param))))
```

```{r avg_samp_dist_subs}
ss_samp_dist_exp1 <- df_sampling_exp1 %>%
    filter(trial_training_block == "active") %>%
    group_by(subids, condition, block, category_type, experiment) %>%
    summarise(mean_samp_dist = mean(samp_dist_odb),
              ci_high_msd = ci.high(samp_dist_odb),
              ci_low_msd = ci.low(samp_dist_odb))

ss_mean_acc_active_block_exp1 <- df_rep_all %>%
    filter(trial_training_block == "active", trial_type == "test") %>%
    group_by(subids, condition, block, category_type, experiment) %>%
    summarise(mean_accuracy_active_block = mean(correct),
              ci_high_acc_active_block = ci.high(correct),
              ci_low_acc_active_block = ci.low(correct))

ss_mean_acc_all_exp1 <- df_rep_all %>%
    filter(trial_type == "test") %>%
    group_by(subids, condition, category_type, experiment) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high_acc = ci.high(correct),
              ci_low_acc = ci.low(correct))

# join sampling and test acc together
ss_all_exp1 <- left_join(ss_samp_dist_exp1, ss_mean_acc_active_block_exp1, 
                         by=c("subids", "condition", "block", "category_type", "experiment"))

ss_all_exp1 <- left_join(ss_all_exp1, ss_mean_acc_all_exp1, 
                         by=c("subids", "condition", "category_type", "experiment"))
```

```{r exp1a_sampling_mixed_model}
lmodel_samp_exp1a <- lm(mean_accuracy ~ mean_samp_dist, 
                             data=filter(ss_all_exp1, experiment == "replication_1a"))
```

We were also interested in the relationship between participants' overall sampling behavior and learning outcomes. We follow @markant2014better and quantify the quality of a sample based on its orthogonal distance from the true category boundary, with samples closer to the boundary being of higher quality. For each participant, we computed a mean accuracy score and a mean sample distance score, and fit a linear model using sample distance to predict accuracy. We found a signficant effect of sample distance ($\beta$ = -.0003, p < .001) with accuracy increasing as mean sample distance decreased. 

Taken together, our data provide strong evidence for a successful replication of the original results reported in @markant2014better. We found a comparable advantage in overall classification accuracy for active learners over receptive learners in a web-based experiment with two fewer training/test trial blocks. Our results differ from the original study in that we found an immediate advantage for active learners after the first block that was not present in the original study. Next we attempt to replicate @markant2014better's findings for the II category structure and for the yoked passive learning condition.

# Experiment 1b

The goals of Experiment 1b are to (a) replicate @markant2014better's findings for the more difficult Information-Integration (II) category structure, and (b) replicate the finding that passive learners did not benefit from being "yoked" to active learners' data.\footnote{Yoked designs are important because they help dissociate the effects of selection from the effects of seeing better data.} They did not find an active learning advantage for the II category structure and yoked learners were worse than active learners even though they had seen the exact same learning information. We used the same stimuli and followed the exact procedures as the original study (described below). However, we reduced the length of the experiment to two blocks. We made this decision based on finding an immediate active learning advantage in Experiment 1a.


```{r rep1b-data}
df_rep1b <- df %>% 
    filter(experiment == "replication_1b", 
           condition_short %in% c("A","R","Y")) 
```

## Methods

### Stimuli
Visual stimuli were identical to Experiment 1a.

### Participants

```{r rep1b-participants}
demographics_replication_1b <- df_rep1b %>% 
    distinct(subids) %>% 
    xtabs(formula = ~ condition_long + category_type_string) %>% 
    as.data.frame() %>% 
    rename(count = Freq)

dnu_exp1b <- df_rep1b %>% distinct(subids) %>% count(understand) %>% filter(understand == "No")

# get num subs in each condition
nsubs_active_ii_rep_1b <- demographics_replication_1b$count[1]
nsubs_passive_ii_rep_1b <- demographics_replication_1b$count[2]
nsubs_yoked_ii_rep_1b <- demographics_replication_1b$count[3]

nsubs_active_rb_rep_1b <- demographics_replication_1b$count[4]
nsubs_passive_rb_rep_1b <- demographics_replication_1b$count[5]
nsubs_yoked_rb_rep_1b <- demographics_replication_1b$count[6]
```

Participant recruitment and inclusionary/exclusionary criteria were identical to those of Experiment 1a (excluded `r dnu_exp1b` HITs). `r sum(demographics_replication_1b$count)` HITs were posted across each of the between-subjects conditions: two category structures (II and RB) and three training conditions (Active, Passive, and Yoked).

```{r data-filter-1b}
df_rep1b %<>% filter(understand != "No")
```

### Design and procedure

Procedures were identical to those of Experiment 1a. We added a "yoked" learning condition, in which we match each passive learning participant with training data generated from an active learning participant's sampling behavior. Thus, both the active and yoked participants saw the exact same data, but the active participants were in control of the information flow.

## Results and Discussion

### Overall classification accuracy

```{r rep1b-mean-acc}
ms_rep_1b <- df_rep1b %>%
    filter(trial_type == "test") %>%
    group_by(condition_short, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))
```

```{r rep1b-acc-plot, fig.env = "figure", fig.pos = "t", fig.width=3.5, fig.height=2.3, fig.align='center', set.cap.width=T, num.cols.cap=1, fig.cap = "The left panel shows overall accuracy performance for the Active and Passive training conditions. The right panel shows participants' accuracy across both blocks in the experiment."}

ggplot(aes(x=condition_short, y=mean_accuracy), data=ms_rep_1b) + 
    geom_bar(stat = "identity", aes(fill = condition_short)) + 
    geom_linerange(aes(ymin=mean_accuracy - ci_low, 
                       ymax=mean_accuracy + ci_high), 
                   size=0.6,
                   position=position_dodge(width=0.9)) + 
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    facet_grid(.~category_type) +
    coord_cartesian(ylim=c(0.4,1.0)) +
    scale_fill_solarized() +
    ylab("Mean Accuracy") +
    xlab("Condition") +
    facet_grid(.~category_type) +
    theme(text = element_text(size=16)) +
    guides(fill=F) +
    theme_bw()

```

```{r rep1b_mixed_model}
mixed_model_exp1b <- glmer(correct ~ condition * category_type + (1|subids), 
            data=filter(df_rep1b, trial_type=="test"), 
            nAGQ = 1,
            control = glmerControl(optimizer = "bobyqa"),
            family=binomial)
```

Figure 3 shows the overall effect of category structure and training condition on participants' accuracy performance. We fit the same logistic regression as specified in Experiment 1a. We found a significant main effect of category structure ($\beta$ = `r round(summary(mixed_model_exp1b)$coef[4], 2)`, p < .001) with better performance in the RB category structure, and a significant main effect of condition ($\beta$ = `r round(summary(mix_model_exp1a)$coef[2], 2)`, p < .001) such that participants in the passive and yoked conditions performed worse than participants in the active condition. We did not find any significant interactions. 

### Relationship between sampling and test across blocks

```{r exp1b_sampling_model}
lmodel_sampling_all <- lm(mean_accuracy ~ mean_samp_dist * as.factor(block), 
                             data=filter(ss_all_exp1, block %in% c(1,2)))
```

Since the main goal of this work was to test different sequences of active/passive learning, we were interested in exploring the relations between participants' sampling behavior and test accuracy *over time* in this task. To explore these relations, we performed an exploratory analysis where we fit a linear model predicting each participant's mean accuracy based on the quality of their sampling behavior and block. As expected participants' accuracy improved in the second block ($\beta$ = `r round(summary(lmodel_sampling_all)$coef[3], 2)`, p = `r round(summary(lmodel_sampling_all)$coef[3,4], 2)`). There was a significant two-way interaction between sampling distance and block ($\beta$ = -0.0013, p = `r round(summary(lmodel_sampling_all)$coef[3,4], 3)`) such that the relationship between quality of sampling and accuracy did not emerge until the second block. Figure 4 shows this interaction.

TODO: quick recap and then transition to Experiment 2.

```{r exp1_sampling-acc-plot, fig.env = "figure", fig.pos = "h", fig.width=3.5, fig.height=2.5, fig.align='center', set.cap.width=T, num.cols.cap=1, fig.cap = "The relations between quality of sampling and accuracy on test trials across blocks."}

ggplot(aes(x=mean_samp_dist, y=mean_accuracy_active_block), 
                 data = filter(ss_all_exp1, block %in% c(1, 2))) +
    geom_point() +
    geom_smooth(method="lm") +
    facet_grid(.~block) +
    xlab("Mean Sample Distance") +
    ylab("Mean Accuracy") +
    theme(text = element_text(size=16)) +
    theme_bw()

```

# Experiment 2

TODO: introduce experiment 2.

```{r seq-data}
df_sequence <- df %>% filter(block == 1 | block == 2,
                             experiment == "sequence",
                             condition %in% c("RA", "AR"))

df_sequence_rep <- df %>% filter(block == 1 | block == 2,
                             condition %in% c("RA", "AR", "RR", "AA"))
```

## Methods

### Stimuli
Stimuli were identical to Experiment 1.  

### Participants

```{r seq-participants}
demographics_sequence <- df_sequence %>% 
    distinct(subids) %>% 
    xtabs(formula = ~ condition_long + category_type_string) %>% 
    as.data.frame() %>% 
    rename(count = Freq)

dnu_sequence <- df_sequence %>% distinct(subids) %>% 
    count(understand) %>% 
    filter(understand == "No")

# get num subs in each condition
nsubs_ar_ii <- demographics_sequence$count[1]
nsubs_ra_ii <- demographics_sequence$count[2]

nsubs_ar_rb <- demographics_sequence$count[3]
nsubs_ra_rb <- demographics_sequence$count[4]
```

Participant recruitment and inclusionary/exclusionary criteria were identical to those of Experiment 1 (`r dnu_sequence` HITs). Approximately 44 HITs were posted for each condition for total of `r sum(demographics_sequence$count)` paid HITs.

```{r seq-data-filter}
df_sequence <- df_sequence %>% filter(understand != "No")
df_sequence_rep <- df_sequence_rep %>% filter(understand != "No")
```

### Design and procedure

Procedures were identical to those of Experiment 1. Participants were randomly assigned to one the two between-subjects conditions: Active-Receptive (AR) vs. Receptive-Active (RA). In the AR condition, participants completed a block of active learning then proceeded to a block of passive learning. In the RA condition, the order of the blocks was flipped. 

## Results and Discussion

```{r seq-acc-computation}
# overall acc
ms_sequence_all <- df_sequence_rep %>%
    filter(trial_type == "test") %>%
    group_by(condition, category_type) %>%
    summarise(mean_accuracy = mean(correct),
              ci_high = ci.high(correct),
              ci_low = ci.low(correct))
```

```{r exp2_acc_plot, fig.env = "figure*", fig.pos = "t", fig.width=5, fig.height=3, fig.align='center', set.cap.width=T, num.cols.cap=2, fig.cap = "The left panel shows accuracy performance across both blocks for the different sequence of active/passive training. The right panel shows overall accuracy performance plotted with the active-active and receptive-receptive data from Experiment 1."}

ggplot(aes(x=condition, y=mean_accuracy), data=ms_sequence_all) + 
    geom_bar(stat = "identity", aes(fill = condition)) + 
    geom_linerange(aes(ymin=mean_accuracy - ci_low, 
                       ymax=mean_accuracy + ci_high), 
                   size=0.6,
                   position=position_dodge(width=0.9)) + 
    facet_grid(.~category_type) +
    coord_cartesian(ylim=c(0.5,0.9)) +
    scale_fill_solarized() +
    ylab("Mean Accuracy") +
    xlab("Condition") +
    theme(text = element_text(size=16)) +
    guides(fill=F) +
    theme_bw()
```

```{r mixed-model-seq}
mixed_model_seq <- glmer(correct ~ condition * category_type * block + (1|subids), 
                              data=filter(df_sequence, trial_type=="test"), 
                              nAGQ = 0,
                              control = glmerControl(optimizer = "bobyqa"),
                              family=binomial)
```

```{r mixed-model-seq-full}
# effect code (choose contrasts based on how you want to interpret model output)
df_sequence_rep %<>% mutate(category_type = factor(category_type),
               condition = factor(condition),
               block_factor = factor(block))

contrasts(df_sequence_rep$category_type) <- cbind("base=rb" = c(1, -1))
contrasts(df_sequence_rep$block_factor) <- cbind("base=block1" = c(-1, 1))
contrasts(df_sequence_rep$condition) <- cbind("active_vs_passive" = c(1, 1, 1, -3), 
                                              "active2_vs_active1" = c(2, -1, -1, -0),
                                              "ra_vs_ar" = c(0, 1, -1, 0))

mixed_model_seq_full <- glmer(correct ~ condition * category_type * block + (1|subids), 
                              data=filter(df_sequence_rep, trial_type=="test"), 
                              nAGQ = 0,
                              control = glmerControl(optimizer = "bobyqa"),
                              family=binomial)
```

Intercept is the mean of the means (or the grand mean) of all the groups. These data are unbalanced.
Active better than passive. Information integration worse than rule-based.

# General Discussion

* Recap findings
    * Active learning advantage in a direct replication 
    * Passive-active better than Active-passive
    * Conceptual replication
    
* Expand on why we see AR > RA
    * Sequential hypothesis testing model 
    * Gain some understanding of task before exploring
    * RA is bad because you can't refine your current hypothesis. Can only use the data you are given
    to confirm/reject current hypothesis
    
    
Moreover, there are markedly different costs associated with active compared to passive learning, with active learning requiring more effort and time on the part of the learner. Thus, understanding how different sequences of active/passive learning interact to affect learning outcomes is an important question for both theoretical and applied reasons.  


* Limitations
    * AA was always best
    * task analysis 
    * complexity of real world learning
    
* Takeaway point: 

# Acknowledgements

We are grateful to Doug Markant and Todd Gureckis for sharing the details and code from the original experiment. We thank the members of the Language and Cognition Lab for their helpful feedback on this project. This work was supported by a National Science Foundation Graduate Research Fellowship to KM.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
